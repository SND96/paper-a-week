<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Paper a Week  | Experience Replay for Continual Learning</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.59.1" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="https://snd96.github.io/paper-a-week/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    
    
    <meta property="og:title" content="Experience Replay for Continual Learning" />
<meta property="og:description" content="Experience Replay for Continual Learning https://arxiv.org/pdf/1811.11682.pdf
Problem
 In settings where gathering new experience is expensive/difficult it is imperative to retain gained knowledge while learning only from one task at a time. Boundaries between different tasks will not be persistent and this leads to the danger of catastrophic forgetting where an agent forgets what it has learned previously when it encounteres a new situtation  Solution
 An ideal continual learning system must satisfy three requirements." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://snd96.github.io/paper-a-week/papers/experience-replay-for-continual-learning/" />
<meta property="article:published_time" content="2019-11-24T08:47:11+01:00" />
<meta property="article:modified_time" content="2019-11-24T08:47:11+01:00" />
<meta itemprop="name" content="Experience Replay for Continual Learning">
<meta itemprop="description" content="Experience Replay for Continual Learning https://arxiv.org/pdf/1811.11682.pdf
Problem
 In settings where gathering new experience is expensive/difficult it is imperative to retain gained knowledge while learning only from one task at a time. Boundaries between different tasks will not be persistent and this leads to the danger of catastrophic forgetting where an agent forgets what it has learned previously when it encounteres a new situtation  Solution
 An ideal continual learning system must satisfy three requirements.">


<meta itemprop="datePublished" content="2019-11-24T08:47:11&#43;01:00" />
<meta itemprop="dateModified" content="2019-11-24T08:47:11&#43;01:00" />
<meta itemprop="wordCount" content="443">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Experience Replay for Continual Learning"/>
<meta name="twitter:description" content="Experience Replay for Continual Learning https://arxiv.org/pdf/1811.11682.pdf
Problem
 In settings where gathering new experience is expensive/difficult it is imperative to retain gained knowledge while learning only from one task at a time. Boundaries between different tasks will not be persistent and this leads to the danger of catastrophic forgetting where an agent forgets what it has learned previously when it encounteres a new situtation  Solution
 An ideal continual learning system must satisfy three requirements."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://snd96.github.io/paper-a-week/" class="f3 fw2 hover-white no-underline white-90 dib">
      Paper a Week
    </a>
    <div class="flex-l items-center">
      

      
      











    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        PAPERS
      </p>
      <h1 class="f1 athelas mb1">Experience Replay for Continual Learning</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2019-11-24T08:47:11&#43;01:00">November 24, 2019</time>
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><h1 id="experience-replay-for-continual-learning">Experience Replay for Continual Learning</h1>

<p><a href="https://arxiv.org/pdf/1811.11682.pdf">https://arxiv.org/pdf/1811.11682.pdf</a></p>

<p><strong>Problem</strong></p>

<ul>
<li>In settings where gathering new experience is expensive/difficult it is imperative to retain gained knowledge while learning only from one task at a time.</li>
<li>Boundaries between different tasks will not be persistent and this leads to the danger of <em>catastrophic forgetting</em> where an agent forgets what it has learned previously when it encounteres a new situtation</li>
</ul>

<p><strong>Solution</strong></p>

<ul>
<li>An ideal continual learning system must satisfy three requirements.

<ul>
<li>Retain learned capacities. Should not be any degradation in task performance when a previously seen task is encountered.</li>
<li>Maintenance of old skills should not negatively impact the acquisition of new skills or knowledge</li>
<li>If possible, continual learning should use previously learned tasks to learn new tasks faster through constructive interference or positive transfer.</li>
</ul></li>
<li>The paper proposes Continual Learning with Experience and Replay (CLEAR). Uses a mixture of novel experience on-policy and replay experience off-policy for both maintenance of performance on earlier tasks and rapid adaptation to new tasks.</li>
</ul>

<p><strong>CLEAR</strong></p>

<ul>
<li>CLEAR uses actor-critic training on a mixture of new and replayed experiences.</li>
<li>For replay experiences, does behavioral cloning between the network and its past self to prevent network output on replayed tasks from drifting while learning new tasks.</li>
<li>The cloning is done on both policy and value and is implemented as a loss.</li>
</ul>

<p><figure><img src="https://snd96.github.io/paper-a-week/attachments/e18afcdb.png" alt="e18afcdb.png"></figure></p>

<p><strong>Discussion of Results</strong></p>

<ul>
<li>The paper details three different methods of training on 3 separate but related image processing tasks

<ul>
<li>Separate training where multiples networks is trained on each task separately.</li>
<li>Simulataneous training where a single network trains on all tasks simultaneously</li>
<li>Cyclic training where the network cycles through each task sequentially.</li>
</ul></li>
<li>While separate and simulataneous training were similar in output, cyclic training results in catastrophic interference with vanilla training.</li>
<li>The use of CLEAR alleviates this problem and the task performance is closer to separate and simulataneous training.</li>
<li>Balance of on- and off-policy learning:

<ul>
<li>Ratio of new examples to replay examples effect on training is observed. With 100 percent new, this results in catastrophic forgetting. 75-25 ratio gives a goood resistance to forgetting while 100 percent training results in no forgetting but with some dip in performance</li>
<li>50-50 was found to be the ideal ratio.</li>
</ul></li>
<li>Limited-size buffers

<ul>
<li>Buffer size of replay experience was varied between 50 million and 5 with very little pereformance drop.</li>
</ul></li>
<li>CLEAR also succeeds in learning a new task very quickly. The new task is inserted in the the cyclic sequence as a probe.</li>
</ul>

<p><strong>Extensions</strong></p>

<ul>
<li>Algorithm that both remembers and selectively forgets certain tasks that are no longer needed or have changed drastically.</li>
<li>This happens when the action space of a task is changed during training and hence the agent needs to overwrite previously learned skills.</li>
</ul>
<ul class="pa0">
  
</ul>
<div class="mt6">
      
      
      </div>
    </section>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <html>
<body>
<footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://snd96.github.io/paper-a-week/" >
    &copy; 2020 Paper a Week
  </a>
    <div>










</div>
  </div>
</footer>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


    

  <script src="https://snd96.github.io/paper-a-week/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
